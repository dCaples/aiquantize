{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random MIDI file: ./lmd_full/6/60f4f7f37aa4dae34d541673cfc956ff.mid\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import pretty_midi\n",
    "\n",
    "def get_random_midi_file(root_dir):\n",
    "    midi_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "\n",
    "            if filename.endswith('.mid') or filename.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(dirpath, filename))\n",
    "    \n",
    "    if not midi_files:\n",
    "        raise FileNotFoundError(f\"No MIDI files found in {root_dir}\")\n",
    "    \n",
    "    return random.choice(midi_files)\n",
    "\n",
    "# Usage\n",
    "root_directory = './lmd_full'\n",
    "random_midi_file = get_random_midi_file(root_directory)\n",
    "print(f\"Random MIDI file: {random_midi_file}\")\n",
    "\n",
    "filename = random_midi_file\n",
    "\n",
    "def get_random_pretty_midi_file():\n",
    "    filename = get_random_midi_file(root_directory)\n",
    "    return pretty_midi.PrettyMIDI(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegocaples/miniconda3/envs/ai/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error reading file: data byte must be in range 0..127\n",
      "Error reading file: data byte must be in range 0..127\n",
      "Total memory used: 5545296 bytes\n",
      "Total memory used: 5.2884063720703125 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "def process_midi_data(midi_data):\n",
    "    song = []\n",
    "    time_per_quarter_note = midi_data.tick_to_time(midi_data.resolution)\n",
    "    for i, instrument in enumerate(midi_data.instruments):\n",
    "        for note in instrument.notes:\n",
    "            track = i\n",
    "            start = note.start\n",
    "            duration = note.end - note.start\n",
    "            pitch = note.pitch\n",
    "\n",
    "            notedata = [track, start, duration, pitch]\n",
    "            song.append(notedata)\n",
    "        # sort by start time\n",
    "        song.sort(key=lambda x: x[1])\n",
    "        # prepend the time_per_quarter_note\n",
    "    song.insert(0, [time_per_quarter_note, 0, 0, 0])\n",
    "    return torch.tensor(song, dtype=torch.float32)\n",
    "\n",
    "song_lengths = []\n",
    "songs = []\n",
    "for i in range(100):\n",
    "    try:\n",
    "        midi_data = get_random_pretty_midi_file()\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "        continue\n",
    "\n",
    "    song = process_midi_data(midi_data)\n",
    "    songs.append(song)\n",
    "\n",
    "def get_memory_used(tensor):\n",
    "    return tensor.element_size() * tensor.nelement()\n",
    "\n",
    "total_memory = 0\n",
    "for song in songs:\n",
    "    total_memory += get_memory_used(song)\n",
    "\n",
    "print(f\"Total memory used: {total_memory} bytes\")\n",
    "# in MB\n",
    "print(f\"Total memory used: {total_memory / 1024 / 1024} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TPQN: 96\n",
      "Time per tick: 0.005208333333333333\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "\n",
    "        \n",
    "\n",
    "def process_midi(filename, track_index=0):\n",
    "    # Load the MIDI file\n",
    "    midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "\n",
    "    # Print the TPQN (Ticks Per Quarter Note)\n",
    "    print(\"TPQN:\", midi_data.resolution)\n",
    "\n",
    "    # Print the time per tick\n",
    "    time_per_tick = midi_data.tick_to_time(1)\n",
    "    print(\"Time per tick:\", time_per_tick)\n",
    "\n",
    "    # Get the specified track of the MIDI file\n",
    "    track = midi_data.instruments[track_index]\n",
    "\n",
    "    # Get all the \"note on\" messages in the track\n",
    "    note_on_messages = [note for note in track.notes if note.velocity > 0]\n",
    "\n",
    "    # Assuming 4/4 time signature\n",
    "    ticks_per_measure = 4 * midi_data.resolution\n",
    "\n",
    "    # Create a list to store the annotated notes\n",
    "    annotated_notes = []\n",
    "\n",
    "    # Iterate over each note on message\n",
    "    for i, note in enumerate(note_on_messages):\n",
    "        # Get the measure index of the note\n",
    "        tick = midi_data.time_to_tick(note.start)\n",
    "        measure_index = tick // ticks_per_measure\n",
    "\n",
    "        # Get the ticks since the last measure for the note\n",
    "        ticks_since_last_measure = tick % ticks_per_measure\n",
    "\n",
    "        # Get the ticks since the last note\n",
    "        if i > 0:\n",
    "            ticks_since_last_note = tick - midi_data.time_to_tick(note_on_messages[i-1].start)\n",
    "        else:\n",
    "            ticks_since_last_note = tick\n",
    "\n",
    "        # Create a dictionary to store the annotated note information\n",
    "        annotated_note = {\n",
    "            'note': note,\n",
    "            'measure_index': measure_index,\n",
    "            'ticks_since_last_measure': ticks_since_last_measure,\n",
    "            'ticks_since_last_note': ticks_since_last_note\n",
    "        }\n",
    "\n",
    "        # Append the annotated note to the list\n",
    "        annotated_notes.append(annotated_note)\n",
    "\n",
    "    # Print the first 10 annotated notes\n",
    "    # for i, annotated_note in enumerate(annotated_notes[:10]):\n",
    "    #     print(\"Note:\", annotated_note['note'])\n",
    "    #     print(\"Measure Index:\", annotated_note['measure_index'])\n",
    "    #     print(\"Ticks since last measure:\", annotated_note['ticks_since_last_measure'])\n",
    "    #     print(\"Ticks since last note:\", annotated_note['ticks_since_last_note'])\n",
    "    #     print(\"---\")\n",
    "\n",
    "    return annotated_notes\n",
    "\n",
    "# Usage\n",
    "filename = random_midi_file\n",
    "track_index = 0\n",
    "\n",
    "annotated_notes = process_midi(filename, track_index)\n",
    "print(len(annotated_notes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pretty_midi\n",
    "\n",
    "# class for a song\n",
    "\n",
    "class Song:\n",
    "    def __init__(self, filename):\n",
    "        midi_data = pretty_midi.PrettyMIDI(filename)\n",
    "        self.time_per_measure = midi_data.tick_to_time(midi_data.resolution * 4)\n",
    "        self.tracks = []\n",
    "        for track in midi_data.instruments:\n",
    "            track_data = []\n",
    "            for note in track.notes:\n",
    "                start_tick = note.start\n",
    "                pitch = note.pitch\n",
    "                track_data.append([start_tick, pitch])\n",
    "            # add the track data to the list of tracks in a torch tensor\n",
    "            self.tracks.append(torch.tensor(track_data, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pool' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 23\u001b[0m\n\u001b[1;32m     20\u001b[0m songs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m errors_processing \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPool\u001b[49m(cpu_count()) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[1;32m     24\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tqdm(pool\u001b[38;5;241m.\u001b[39mimap(process_midi_file, midi_files), total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(midi_files)))\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m song, error \u001b[38;5;129;01min\u001b[39;00m results:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Pool' is not defined"
     ]
    }
   ],
   "source": [
    "def process_midi_file(filename):\n",
    "    try:\n",
    "        song = Song(filename)\n",
    "        return song, None\n",
    "    except Exception as e:\n",
    "        return None, e\n",
    "\n",
    "def collect_midi_files(root_directory):\n",
    "    midi_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_directory):\n",
    "        for filename in filenames:\n",
    "            if filename.endswith('.mid') or filename.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(dirpath, filename))\n",
    "    return midi_files\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    root_directory = './lmd_full'\n",
    "    midi_files = collect_midi_files(root_directory)\n",
    "\n",
    "    songs = []\n",
    "    errors_processing = 0\n",
    "\n",
    "    with Pool(cpu_count()) as pool:\n",
    "        results = list(tqdm(pool.imap(process_midi_file, midi_files), total=len(midi_files)))\n",
    "\n",
    "    for song, error in results:\n",
    "        if song:\n",
    "            songs.append(song)\n",
    "        if error:\n",
    "            errors_processing += 1\n",
    "\n",
    "    print(f\"Errors processing: {errors_processing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of MIDI files: 178561\n",
      "MThd not found. Probably not a MIDI file\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegocaples/miniconda3/envs/ai/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of notes: 380165\n",
      "notes per file: 3801.65\n"
     ]
    }
   ],
   "source": [
    "import pretty_midi\n",
    "import os\n",
    "root_directory = './lmd_full'\n",
    "midi_files = []\n",
    "for dirpath, _, filenames in os.walk(root_directory):\n",
    "    for filename in filenames:\n",
    "\n",
    "        if filename.endswith('.mid') or filename.endswith('.midi'):\n",
    "            midi_files.append(\n",
    "                os.path.join(dirpath, filename)\n",
    "            )\n",
    "\n",
    "songs_to_count = 100\n",
    "print(f\"Total number of MIDI files: {len(midi_files)}\")\n",
    "errors_processing = 0\n",
    "total_number_of_notes = 0\n",
    "for i, midi_data in enumerate(midi_files):\n",
    "    try:\n",
    "        # get the total number of notes\n",
    "        notes_per_song = 0\n",
    "        midi_file = pretty_midi.PrettyMIDI(midi_data)\n",
    "        for track in midi_file.instruments:\n",
    "            notes_per_song += len(track.notes)\n",
    "        # print(f\"notes per song: {notes_per_song}\")\n",
    "        total_number_of_notes += notes_per_song\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        errors_processing += 1\n",
    "    if i > songs_to_count:\n",
    "        break\n",
    "\n",
    "    \n",
    "print(f\"Total number of notes: {total_number_of_notes}\")\n",
    "notes_per_file = total_number_of_notes / songs_to_count\n",
    "print(f\"notes per file: {notes_per_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "songs = []\n",
    "errors_processing = 0\n",
    "for midi_data in tqdm(midi_files):\n",
    "    try:\n",
    "        song = Song(midi_data)\n",
    "        songs.append(song)\n",
    "    except Exception as e:\n",
    "        errors_processing += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n",
      "torch.Size([4, 3, 32, 32]) torch.Size([4])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = {'data': self.data[idx], 'label': self.labels[idx]}\n",
    "        return sample\n",
    "\n",
    "# Generate some random data\n",
    "data = torch.randn(100, 3, 32, 32)  # 100 samples, 3 channels, 32x32 images\n",
    "labels = torch.randint(0, 10, (100,))  # 100 labels for 10 classes\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MyDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# Iterate through the dataloader\n",
    "for batch in dataloader:\n",
    "    data_batch = batch['data']\n",
    "    labels_batch = batch['label']\n",
    "    print(data_batch.shape, labels_batch.shape)\n",
    "    # Add your training code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SongData(Dataset):\n",
    "    def __init__(self, songs):\n",
    "        self.songs = songs\n",
    "        self.global_track_id_to_song_id = []\n",
    "        for i, song in enumerate(songs):\n",
    "            for track in song.instruments:\n",
    "                self.global_track_id_to_song_id.append(i)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.global_track_id_to_song_id)\n",
    "\n",
    "    def __getitem__(self, instance_idx):  \n",
    "        song_idx = self.global_track_id_to_song_id[instance_idx]\n",
    "        song = self.songs[song_idx]\n",
    "        track_idx = instance_idx - song_idx\n",
    "        sample = {'data': self.data[idx], 'label': self.labels[idx]}\n",
    "        return sample\n",
    "\n",
    "# Generate some random data\n",
    "data = torch.randn(100, 3, 32, 32)  # 100 samples, 3 channels, 32x32 images\n",
    "labels = torch.randint(0, 10, (100,))  # 100 labels for 10 classes\n",
    "\n",
    "# Create dataset and dataloader\n",
    "dataset = MyDataset(data, labels)\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# Iterate through the dataloader\n",
    "for batch in dataloader:\n",
    "    data_batch = batch['data']\n",
    "    labels_batch = batch['label']\n",
    "    print(data_batch.shape, labels_batch.shape)\n",
    "    # Add your training code here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4972757\n",
      "TPQN: 384\n",
      "Time per tick: 0.0015625\n",
      "103823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Instrument(program=57, is_drum=False, name=\"Melodie 4\"),\n",
       " Instrument(program=42, is_drum=False, name=\"Violoncl2\"),\n",
       " Instrument(program=24, is_drum=False, name=\"GuitarAc3\"),\n",
       " Instrument(program=24, is_drum=False, name=\"GuitarAc5\")]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from collections import deque\n",
    "\n",
    "def get_recursive_size(obj, seen=None):\n",
    "    \"\"\"Recursively finds the total memory usage of an object.\"\"\"\n",
    "    if seen is None:\n",
    "        seen = set()\n",
    "    \n",
    "    obj_id = id(obj)\n",
    "    \n",
    "    if obj_id in seen:\n",
    "        return 0\n",
    "    \n",
    "    seen.add(obj_id)\n",
    "    \n",
    "    size = sys.getsizeof(obj)\n",
    "    \n",
    "    if isinstance(obj, dict):\n",
    "        size += sum(get_recursive_size(v, seen) for v in obj.values())\n",
    "        size += sum(get_recursive_size(k, seen) for k in obj.keys())\n",
    "    elif hasattr(obj, '__dict__'):\n",
    "        size += get_recursive_size(obj.__dict__, seen)\n",
    "    elif hasattr(obj, '__iter__') and not isinstance(obj, (str, bytes, bytearray)):\n",
    "        size += sum(get_recursive_size(i, seen) for i in obj)\n",
    "    \n",
    "    return size\n",
    "\n",
    "# Example usage\n",
    "example_object = [1, 2, {3: \"a\", 4: [\"b\", \"c\"]}]\n",
    "object_1 = [([1.1]*500) for _ in range(1000)]\n",
    "object_2 = [torch.tensor([1.1]*500) for _ in range(1000)]\n",
    "\n",
    "print(\"python\")\n",
    "print(get_recursive_size(object_1))\n",
    "print(\"tensors\")\n",
    "print(get_recursive_size(object_2))\n",
    "\n",
    "# # get the number of instruments\n",
    "# midi_data.instruments\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing All Data into sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of all the filenames\n",
    "import os\n",
    "import random\n",
    "import pretty_midi\n",
    "\n",
    "def get_all_filenames(root_dir):\n",
    "    midi_files = []\n",
    "    for dirpath, _, filenames in os.walk(root_dir):\n",
    "        for filename in filenames:\n",
    "\n",
    "            if filename.endswith('.mid') or filename.endswith('.midi'):\n",
    "                midi_files.append(os.path.join(dirpath, filename))\n",
    "    \n",
    "    if not midi_files:\n",
    "        raise FileNotFoundError(f\"No MIDI files found in {root_dir}\")\n",
    "    return midi_files\n",
    "\n",
    "# Usage\n",
    "root_directory = './lmd_full'\n",
    "files = get_all_filenames(root_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: ./lmd_full/6/659414fa1c3016d94d997128f528a73b.mid\n",
      "first note:\n",
      "track: 2.0\n",
      "start: 3.2987499237060547\n",
      "duration: 3.619999885559082\n",
      "pitch: 60.0\n",
      "\n",
      "second note:\n",
      "track: 2.0\n",
      "start: 3.2987499237060547\n",
      "duration: 3.640000104904175\n",
      "pitch: 72.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pretty_midi\n",
    "def process_midi_data(midi_filename):\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_filename)\n",
    "    except Exception as e:\n",
    "        return None, e\n",
    "    song = []\n",
    "    time_per_quarter_note = midi_data.tick_to_time(midi_data.resolution)\n",
    "    for i, instrument in enumerate(midi_data.instruments):\n",
    "        for note in instrument.notes:\n",
    "            track = i\n",
    "            start = note.start\n",
    "            duration = note.end - note.start\n",
    "            pitch = note.pitch\n",
    "\n",
    "            notedata = [track, start, duration, pitch]\n",
    "            song.append(notedata)\n",
    "        # sort by start time\n",
    "        song.sort(key=lambda x: x[1])\n",
    "        # prepend the time_per_quarter_note\n",
    "    song.insert(0, [time_per_quarter_note, 0, 0, 0])\n",
    "    return torch.tensor(song, dtype=torch.float32), None\n",
    "\n",
    "# Usage\n",
    "filename = random.choice(files)\n",
    "song, error = process_midi_data(filename)\n",
    "print(f\"Filename: {filename}\")\n",
    "\n",
    "# the reuslting format:\n",
    "# header: [time_per_quarter_note, 0, 0, 0]\n",
    "# each note: [track, start, duration, pitch]\n",
    "\n",
    "print(f\"first note:\")\n",
    "print(f\"track: {song[1][0]}\")\n",
    "print(f\"start: {song[1][1]}\")\n",
    "print(f\"duration: {song[1][2]}\")\n",
    "print(f\"pitch: {song[1][3]}\")\n",
    "\n",
    "print(f\"\\nsecond note:\")\n",
    "print(f\"track: {song[2][0]}\")\n",
    "print(f\"start: {song[2][1]}\")\n",
    "print(f\"duration: {song[2][2]}\")\n",
    "print(f\"pitch: {song[2][3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00% complete (0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diegocaples/miniconda3/envs/ai/lib/python3.12/site-packages/pretty_midi/pretty_midi.py:100: RuntimeWarning: Tempo, Key or Time signature change events found on non-zero tracks.  This is not a valid type 0 or type 1 MIDI file.  Tempo, Key or Time Signature may be wrong.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01% complete (1000)\n",
      "0.01% complete (2000)\n",
      "0.02% complete (3000)\n",
      "0.02% complete (4000)\n",
      "0.03% complete (5000)\n",
      "0.03% complete (6000)\n",
      "0.04% complete (7000)\n",
      "0.04% complete (8000)\n",
      "0.05% complete (9000)\n",
      "0.06% complete (10000)\n",
      "0.06% complete (11000)\n",
      "0.07% complete (12000)\n",
      "0.07% complete (13000)\n",
      "0.08% complete (14000)\n",
      "0.08% complete (15000)\n",
      "0.09% complete (16000)\n",
      "0.10% complete (17000)\n",
      "0.10% complete (18000)\n",
      "0.11% complete (19000)\n",
      "0.11% complete (20000)\n",
      "0.12% complete (21000)\n",
      "0.12% complete (22000)\n",
      "0.13% complete (23000)\n",
      "0.13% complete (24000)\n",
      "unusual error: index -16307 is out of bounds for axis 0 with size 14508\n",
      "0.14% complete (25000)\n",
      "0.15% complete (26000)\n",
      "0.15% complete (27000)\n",
      "0.16% complete (28000)\n",
      "0.16% complete (29000)\n",
      "0.17% complete (30000)\n",
      "0.17% complete (31000)\n",
      "0.18% complete (32000)\n",
      "0.18% complete (33000)\n",
      "0.19% complete (34000)\n",
      "0.20% complete (35000)\n",
      "0.20% complete (36000)\n",
      "0.21% complete (37000)\n",
      "0.21% complete (38000)\n",
      "0.22% complete (39000)\n",
      "0.22% complete (40000)\n",
      "0.23% complete (41000)\n",
      "0.24% complete (42000)\n",
      "0.24% complete (43000)\n",
      "0.25% complete (44000)\n",
      "0.25% complete (45000)\n",
      "0.26% complete (46000)\n",
      "0.26% complete (47000)\n",
      "0.27% complete (48000)\n",
      "0.27% complete (49000)\n",
      "0.28% complete (50000)\n",
      "0.29% complete (51000)\n",
      "0.29% complete (52000)\n",
      "0.30% complete (53000)\n",
      "0.30% complete (54000)\n",
      "0.31% complete (55000)\n",
      "0.31% complete (56000)\n",
      "0.32% complete (57000)\n",
      "0.32% complete (58000)\n",
      "0.33% complete (59000)\n",
      "0.34% complete (60000)\n",
      "0.34% complete (61000)\n",
      "0.35% complete (62000)\n",
      "0.35% complete (63000)\n",
      "0.36% complete (64000)\n",
      "unusual error: index -7580 is out of bounds for axis 0 with size 2\n",
      "0.36% complete (65000)\n",
      "0.37% complete (66000)\n",
      "0.38% complete (67000)\n",
      "0.38% complete (68000)\n",
      "0.39% complete (69000)\n",
      "0.39% complete (70000)\n",
      "0.40% complete (71000)\n",
      "0.40% complete (72000)\n",
      "0.41% complete (73000)\n",
      "0.41% complete (74000)\n",
      "0.42% complete (75000)\n",
      "0.43% complete (76000)\n",
      "0.43% complete (77000)\n",
      "0.44% complete (78000)\n",
      "0.44% complete (79000)\n",
      "0.45% complete (80000)\n",
      "0.45% complete (81000)\n",
      "0.46% complete (82000)\n",
      "0.46% complete (83000)\n",
      "0.47% complete (84000)\n",
      "0.48% complete (85000)\n",
      "0.48% complete (86000)\n",
      "0.49% complete (87000)\n",
      "0.49% complete (88000)\n",
      "0.50% complete (89000)\n",
      "0.50% complete (90000)\n",
      "0.51% complete (91000)\n",
      "0.52% complete (92000)\n",
      "0.52% complete (93000)\n",
      "0.53% complete (94000)\n",
      "0.53% complete (95000)\n",
      "0.54% complete (96000)\n",
      "0.54% complete (97000)\n",
      "0.55% complete (98000)\n",
      "0.55% complete (99000)\n",
      "0.56% complete (100000)\n",
      "0.57% complete (101000)\n",
      "0.57% complete (102000)\n",
      "0.58% complete (103000)\n",
      "0.58% complete (104000)\n",
      "0.59% complete (105000)\n",
      "0.59% complete (106000)\n",
      "0.60% complete (107000)\n",
      "0.60% complete (108000)\n",
      "0.61% complete (109000)\n",
      "0.62% complete (110000)\n",
      "0.62% complete (111000)\n",
      "0.63% complete (112000)\n",
      "0.63% complete (113000)\n",
      "0.64% complete (114000)\n",
      "0.64% complete (115000)\n",
      "0.65% complete (116000)\n",
      "0.66% complete (117000)\n",
      "0.66% complete (118000)\n",
      "0.67% complete (119000)\n",
      "0.67% complete (120000)\n",
      "0.68% complete (121000)\n",
      "0.68% complete (122000)\n",
      "0.69% complete (123000)\n",
      "0.69% complete (124000)\n",
      "0.70% complete (125000)\n",
      "0.71% complete (126000)\n",
      "0.71% complete (127000)\n",
      "0.72% complete (128000)\n",
      "0.72% complete (129000)\n",
      "0.73% complete (130000)\n",
      "0.73% complete (131000)\n",
      "0.74% complete (132000)\n",
      "0.74% complete (133000)\n",
      "0.75% complete (134000)\n",
      "0.76% complete (135000)\n",
      "0.76% complete (136000)\n",
      "0.77% complete (137000)\n",
      "0.77% complete (138000)\n",
      "0.78% complete (139000)\n",
      "0.78% complete (140000)\n",
      "0.79% complete (141000)\n",
      "0.80% complete (142000)\n",
      "0.80% complete (143000)\n",
      "0.81% complete (144000)\n",
      "0.81% complete (145000)\n",
      "0.82% complete (146000)\n",
      "0.82% complete (147000)\n",
      "0.83% complete (148000)\n",
      "0.83% complete (149000)\n",
      "0.84% complete (150000)\n",
      "0.85% complete (151000)\n",
      "0.85% complete (152000)\n",
      "0.86% complete (153000)\n",
      "0.86% complete (154000)\n",
      "0.87% complete (155000)\n",
      "0.87% complete (156000)\n",
      "0.88% complete (157000)\n",
      "0.88% complete (158000)\n",
      "0.89% complete (159000)\n",
      "0.90% complete (160000)\n",
      "0.90% complete (161000)\n",
      "0.91% complete (162000)\n",
      "0.91% complete (163000)\n",
      "0.92% complete (164000)\n",
      "0.92% complete (165000)\n",
      "0.93% complete (166000)\n",
      "0.94% complete (167000)\n",
      "0.94% complete (168000)\n",
      "0.95% complete (169000)\n",
      "0.95% complete (170000)\n",
      "0.96% complete (171000)\n",
      "0.96% complete (172000)\n",
      "0.97% complete (173000)\n",
      "0.97% complete (174000)\n",
      "0.98% complete (175000)\n",
      "0.99% complete (176000)\n",
      "0.99% complete (177000)\n",
      "1.00% complete (178000)\n"
     ]
    }
   ],
   "source": [
    "# simple example of loading all the files (single process)\n",
    "errors = []\n",
    "songs = []\n",
    "totalsongs = len(files)\n",
    "for i, file in enumerate(files):\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"{i/totalsongs:.2f}% complete ({i})\")\n",
    "    try:\n",
    "        song, error = process_midi_data(file)\n",
    "        if error is not None:\n",
    "            errors.append(error)\n",
    "            continue\n",
    "        songs.append(song)\n",
    "    except Exception as e:\n",
    "        print(f\"unusual error: {e}\")\n",
    "    # if i > 100:\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of groups to split into\n",
    "num_groups = 10\n",
    "\n",
    "# Calculate the size of each group\n",
    "group_size = len(songs) // num_groups\n",
    "\n",
    "# Save each group directly\n",
    "for i in range(num_groups):\n",
    "    start_idx = i * group_size\n",
    "    end_idx = (i + 1) * group_size if i < num_groups - 1 else len(songs)\n",
    "    torch.save(songs[start_idx:end_idx], f'./dataset/song_group_{i}.pth')\n",
    "\n",
    "# Handle any remaining tensors if the list size isn't perfectly divisible\n",
    "if len(songs) % num_groups != 0:\n",
    "    torch.save(songs[num_groups * group_size:], f'./dataset/song_group_{num_groups - 1}.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Hacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# loading all the data\n",
    "# loaded_song_groups = []\n",
    "# for i in range(num_groups):\n",
    "#     loaded_song_groups.append(torch.load(f'./dataset/song_group_{i}.pth'))\n",
    "\n",
    "# # Optionally, you can concatenate all groups back into a single list if needed\n",
    "# loaded_songs = [song for group in loaded_song_groups for song in group]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Load the first group of tensors\n",
    "first_group = torch.load('./dataset/song_group_0.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.7059,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  1.4118,  0.1765, 43.0000],\n",
       "        [ 0.0000,  1.4118,  1.0588, 55.0000],\n",
       "        ...,\n",
       "        [ 0.0000, 57.9706,  2.6471, 50.0000],\n",
       "        [ 0.0000, 58.0147,  2.6471, 55.0000],\n",
       "        [ 0.0000, 58.0588,  2.6471, 59.0000]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the reuslting format:\n",
    "# header: [time_per_quarter_note, 0, 0, 0]\n",
    "# each note: [track, start, duration, pitch]\n",
    "\n",
    "first_group[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is how the dataset building would work on a mock dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_context_length = 3\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "b = [11, 12, 13, 14, 15, 16, 17, 18]\n",
    "\n",
    "dataset = [a, b]\n",
    "\n",
    "# desired datastructure:\n",
    "# index 1: song [0], notes 0-2\n",
    "# index 2: song [0], notes 2-4\n",
    "# index 3: song [0], notes 4-6\n",
    "# index 4: song [0], notes 6-8\n",
    "# index 5: song [0], notes 8-9\n",
    "# index 6: song [1], notes 0-2\n",
    "# ...\n",
    "\n",
    "# stored in the format: [song_index, note_start_index]\n",
    "\n",
    "# Create the dataset\n",
    "train_idxs = []\n",
    "for i, song in enumerate(dataset):\n",
    "    for j in range(0, len(song), test_context_length):\n",
    "        train_idxs.append([i, j])\n",
    "\n",
    "\n",
    "\n",
    "test_context_length = 3\n",
    "\n",
    "a = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "b = [11, 12, 13, 14, 15, 16, 17, 18]\n",
    "\n",
    "dataset = [a, b]\n",
    "\n",
    "# desired datastructure:\n",
    "# index 1: song [0], notes 0-2\n",
    "# index 2: song [0], notes 2-4\n",
    "# index 3: song [0], notes 4-6\n",
    "# index 4: song [0], notes 6-8\n",
    "# index 5: song [0], notes 8-9\n",
    "# index 6: song [1], notes 0-2\n",
    "# ...\n",
    "\n",
    "# stored in the format: [song_index, note_start_index]\n",
    "\n",
    "# Create the dataset\n",
    "data = []\n",
    "for i, song in enumerate(dataset):\n",
    "    for j in range(len(song) - test_context_length):\n",
    "        if j % test_context_length == 0:\n",
    "            data.append([i, j])\n",
    "\n",
    "\n",
    "def build_idxs(dataset, context_length, ignore_header=True):\n",
    "    idxs = []\n",
    "    if ignore_header:\n",
    "        start_idx = 1\n",
    "    else:\n",
    "        start_idx = 0\n",
    "    for i, song in enumerate(dataset):\n",
    "        for j in range(start_idx, len(song) - context_length, context_length):\n",
    "            idxs.append([i, j])\n",
    "    return idxs\n",
    "\n",
    "# Usage\n",
    "test_context_length = 3\n",
    "dataset = [a, b]\n",
    "train_idxs = build_idxs(dataset, test_context_length)\n",
    "\n",
    "song, note_start = train_idxs[0]\n",
    "dataset[song][note_start:note_start + test_context_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset is the first_group, but remove the first element of each song\n",
    "# first element is the header\n",
    "# each song is a tensor\n",
    "dataset = []\n",
    "for song in first_group:\n",
    "    dataset.append(song)\n",
    "\n",
    "\n",
    "context_length = 128\n",
    "\n",
    "dataset_idxs = build_idxs(dataset, context_length)\n",
    "\n",
    "song, note_start = dataset_idxs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'notes': tensor([[  1,   0,  16,  69],\n",
       "         [  2,   0,  16,  50],\n",
       "         [  3,   0,  16,  38],\n",
       "         [  5,   0,  16,  66],\n",
       "         [  0,  16,  16,  76],\n",
       "         [  1,  16,  16,  72],\n",
       "         [  2,  16,  16,  48],\n",
       "         [  3,  16,  16,  36],\n",
       "         [  5,  16,  16,  67],\n",
       "         [  0,  32,  16,  74],\n",
       "         [  1,  32,  16,  71],\n",
       "         [  2,  32,  16,  43],\n",
       "         [  5,  32,  16,  67],\n",
       "         [  0,  48,  32,  71],\n",
       "         [  1,  48,  16,  67],\n",
       "         [  2,  48,  32,  55],\n",
       "         [  3,  48,  32,  43],\n",
       "         [  5,  48,  16,  62],\n",
       "         [  1,  64,  32,  67],\n",
       "         [  5,  64,  32,  62],\n",
       "         [  0,  80,  12,  71],\n",
       "         [  2,  80,  16,  50],\n",
       "         [  0,  92,   4,  69],\n",
       "         [  0,  96,  12,  67],\n",
       "         [  1,  96,  16,  64],\n",
       "         [  2,  96,  16,  48],\n",
       "         [  5,  96,  16,  60],\n",
       "         [  0, 108,   4,  64],\n",
       "         [  0, 112,  32,  67],\n",
       "         [  1, 112,  16,  62],\n",
       "         [  2, 112,  32,  55],\n",
       "         [  3, 112,  32,  43],\n",
       "         [  5, 112,  16,  59],\n",
       "         [  1, 128,  16,  62],\n",
       "         [  5, 128,  16,  59],\n",
       "         [  0, 144,  16,  62],\n",
       "         [  2, 144,  12,  55],\n",
       "         [  3, 144,  12,  43],\n",
       "         [  5, 144,  16,  59],\n",
       "         [  2, 156,   4,  55],\n",
       "         [  3, 156,   4,  43],\n",
       "         [  0, 160,  16,  67],\n",
       "         [  1, 160,  16,  62],\n",
       "         [  2, 160,  12,  54],\n",
       "         [  3, 160,  12,  42],\n",
       "         [  5, 160,  16,  59],\n",
       "         [  2, 172,   4,  52],\n",
       "         [  3, 172,   4,  40],\n",
       "         [  0, 176,  16,  71],\n",
       "         [  1, 176,  16,  67],\n",
       "         [  2, 176,  32,  50],\n",
       "         [  3, 176,  32,  38],\n",
       "         [  5, 176,  16,  62],\n",
       "         [  0, 192,  16,  71],\n",
       "         [  1, 192,  16,  67],\n",
       "         [  5, 192,  16,  62],\n",
       "         [  0, 208,   8,  69],\n",
       "         [  1, 208,   8,  66],\n",
       "         [  2, 208,  32,  50],\n",
       "         [  3, 208,  32,  38],\n",
       "         [  5, 208,   8,  60],\n",
       "         [  0, 216,   8,  67],\n",
       "         [  1, 216,   8,  64],\n",
       "         [  5, 216,   8,  60],\n",
       "         [  0, 224,  16,  69],\n",
       "         [  1, 224,  16,  66],\n",
       "         [  5, 224,  16,  60],\n",
       "         [  0, 240,  48,  67],\n",
       "         [  1, 240,  16,  62],\n",
       "         [  2, 240,  16,  55],\n",
       "         [  3, 240,  16,  43],\n",
       "         [  5, 240,  16,  59],\n",
       "         [  1, 256,  16,  64],\n",
       "         [  2, 256,  16,  55],\n",
       "         [  3, 256,  16,  48],\n",
       "         [  5, 256,  16,  60],\n",
       "         [  1, 272,  16,  62],\n",
       "         [  2, 272,  16,  55],\n",
       "         [  3, 272,  16,  43],\n",
       "         [  5, 272,  16,  59],\n",
       "         [  0, 304,  16,  71],\n",
       "         [  1, 304, 128,  67],\n",
       "         [  2, 304, 128,  59],\n",
       "         [  3, 304, 128,  50],\n",
       "         [  4, 304, 128,  43],\n",
       "         [  0, 320,  16,  74],\n",
       "         [  0, 336,  24,  74],\n",
       "         [  0, 360,   8,  76],\n",
       "         [  0, 368,  16,  74],\n",
       "         [  0, 384,  32,  71],\n",
       "         [  0, 416,  16,  67],\n",
       "         [  0, 432,  16,  69],\n",
       "         [  2, 432,  32,  57],\n",
       "         [  3, 432,  32,  50],\n",
       "         [  0, 448,  16,  69],\n",
       "         [  0, 464,  16,  67],\n",
       "         [  2, 464,  16,  60],\n",
       "         [  3, 464,  16,  48],\n",
       "         [  0, 480,  16,  69],\n",
       "         [  2, 480,  16,  57],\n",
       "         [  3, 480,  16,  50],\n",
       "         [  0, 496,  48,  71],\n",
       "         [  1, 496,  64,  62],\n",
       "         [  2, 496,  64,  59],\n",
       "         [  3, 496,  64,  50],\n",
       "         [  4, 496,  64,  43],\n",
       "         [  0, 544,  16,  67],\n",
       "         [  0, 560,  16,  71],\n",
       "         [  1, 560, 128,  67],\n",
       "         [  2, 560, 128,  59],\n",
       "         [  3, 560, 128,  50],\n",
       "         [  4, 560, 128,  43],\n",
       "         [  0, 576,  16,  74],\n",
       "         [  0, 592,  24,  74],\n",
       "         [  0, 616,   8,  76],\n",
       "         [  0, 624,  16,  74],\n",
       "         [  0, 640,  32,  71],\n",
       "         [  0, 672,  16,  67],\n",
       "         [  0, 688,  16,  69],\n",
       "         [  1, 688,  32,  66],\n",
       "         [  2, 688,  32,  57],\n",
       "         [  3, 688,  32,  50],\n",
       "         [  5, 688,  32,  62],\n",
       "         [  0, 704,  16,  69],\n",
       "         [  0, 720,  16,  67],\n",
       "         [  1, 720,  16,  64],\n",
       "         [  2, 720,  16,  60],\n",
       "         [  3, 720,  16,  48]], dtype=torch.int32),\n",
       " 'perturbed_notes': tensor([[  1,   3,  16,  69],\n",
       "         [  2,   2,  17,  50],\n",
       "         [  3,   3,  16,  38],\n",
       "         [  5,   0,  15,  66],\n",
       "         [  0,  18,  14,  76],\n",
       "         [  1,  16,  15,  72],\n",
       "         [  2,  16,  16,  48],\n",
       "         [  3,  17,  17,  36],\n",
       "         [  5,  17,  15,  67],\n",
       "         [  0,  30,  13,  74],\n",
       "         [  1,  35,  18,  71],\n",
       "         [  2,  34,  18,  43],\n",
       "         [  5,  32,  16,  67],\n",
       "         [  0,  50,  35,  71],\n",
       "         [  1,  53,  18,  67],\n",
       "         [  2,  50,  32,  55],\n",
       "         [  3,  49,  32,  43],\n",
       "         [  5,  48,  17,  62],\n",
       "         [  1,  65,  31,  67],\n",
       "         [  5,  68,  32,  62],\n",
       "         [  0,  81,  12,  71],\n",
       "         [  2,  81,  14,  50],\n",
       "         [  0,  95,   6,  69],\n",
       "         [  0, 100,  12,  67],\n",
       "         [  1,  98,  19,  64],\n",
       "         [  2,  95,  16,  48],\n",
       "         [  5,  98,  17,  60],\n",
       "         [  0, 107,   4,  64],\n",
       "         [  0, 114,  35,  67],\n",
       "         [  1, 112,  17,  62],\n",
       "         [  2, 114,  32,  55],\n",
       "         [  3, 113,  34,  43],\n",
       "         [  5, 114,  18,  59],\n",
       "         [  1, 130,  17,  62],\n",
       "         [  5, 129,  15,  59],\n",
       "         [  0, 146,  15,  62],\n",
       "         [  2, 146,  12,  55],\n",
       "         [  3, 147,  11,  43],\n",
       "         [  5, 146,  16,  59],\n",
       "         [  2, 159,   4,  55],\n",
       "         [  3, 160,   3,  43],\n",
       "         [  0, 160,  13,  67],\n",
       "         [  1, 162,  14,  62],\n",
       "         [  2, 162,  12,  54],\n",
       "         [  3, 163,  13,  42],\n",
       "         [  5, 162,  19,  59],\n",
       "         [  2, 172,   2,  52],\n",
       "         [  3, 177,   5,  40],\n",
       "         [  0, 178,  17,  71],\n",
       "         [  1, 180,  15,  67],\n",
       "         [  2, 178,  31,  50],\n",
       "         [  3, 178,  34,  38],\n",
       "         [  5, 177,  17,  62],\n",
       "         [  0, 192,  20,  71],\n",
       "         [  1, 193,  15,  67],\n",
       "         [  5, 195,  14,  62],\n",
       "         [  0, 207,   8,  69],\n",
       "         [  1, 209,  11,  66],\n",
       "         [  2, 214,  33,  50],\n",
       "         [  3, 209,  33,  38],\n",
       "         [  5, 212,   9,  60],\n",
       "         [  0, 217,   6,  67],\n",
       "         [  1, 215,   9,  64],\n",
       "         [  5, 218,   8,  60],\n",
       "         [  0, 225,  19,  69],\n",
       "         [  1, 227,  17,  66],\n",
       "         [  5, 224,  17,  60],\n",
       "         [  0, 242,  49,  67],\n",
       "         [  1, 245,  18,  62],\n",
       "         [  2, 244,  17,  55],\n",
       "         [  3, 240,  14,  43],\n",
       "         [  5, 241,  15,  59],\n",
       "         [  1, 259,  14,  64],\n",
       "         [  2, 257,  16,  55],\n",
       "         [  3, 258,  16,  48],\n",
       "         [  5, 255,  17,  60],\n",
       "         [  1, 276,  14,  62],\n",
       "         [  2, 274,  13,  55],\n",
       "         [  3, 272,  15,  43],\n",
       "         [  5, 272,  16,  59],\n",
       "         [  0, 306,  14,  71],\n",
       "         [  1, 305, 127,  67],\n",
       "         [  2, 305, 127,  59],\n",
       "         [  3, 307, 128,  50],\n",
       "         [  4, 302, 130,  43],\n",
       "         [  0, 319,  17,  74],\n",
       "         [  0, 338,  24,  74],\n",
       "         [  0, 362,   9,  76],\n",
       "         [  0, 371,  15,  74],\n",
       "         [  0, 387,  30,  71],\n",
       "         [  0, 418,  16,  67],\n",
       "         [  0, 435,  18,  69],\n",
       "         [  2, 432,  31,  57],\n",
       "         [  3, 434,  31,  50],\n",
       "         [  0, 449,  15,  69],\n",
       "         [  0, 465,  12,  67],\n",
       "         [  2, 464,  17,  60],\n",
       "         [  3, 467,  21,  48],\n",
       "         [  0, 479,  18,  69],\n",
       "         [  2, 479,  17,  57],\n",
       "         [  3, 483,  14,  50],\n",
       "         [  0, 498,  51,  71],\n",
       "         [  1, 497,  64,  62],\n",
       "         [  2, 494,  64,  59],\n",
       "         [  3, 495,  63,  50],\n",
       "         [  4, 499,  66,  43],\n",
       "         [  0, 546,  15,  67],\n",
       "         [  0, 559,  18,  71],\n",
       "         [  1, 561, 126,  67],\n",
       "         [  2, 561, 130,  59],\n",
       "         [  3, 560, 130,  50],\n",
       "         [  4, 562, 130,  43],\n",
       "         [  0, 575,  15,  74],\n",
       "         [  0, 596,  28,  74],\n",
       "         [  0, 619,   8,  76],\n",
       "         [  0, 623,  13,  74],\n",
       "         [  0, 640,  33,  71],\n",
       "         [  0, 673,  17,  67],\n",
       "         [  0, 690,  15,  69],\n",
       "         [  1, 688,  33,  66],\n",
       "         [  2, 688,  31,  57],\n",
       "         [  3, 692,  31,  50],\n",
       "         [  5, 691,  34,  62],\n",
       "         [  0, 707,  19,  69],\n",
       "         [  0, 724,  15,  67],\n",
       "         [  1, 721,  17,  64],\n",
       "         [  2, 720,  16,  60],\n",
       "         [  3, 721,  16,  48]], dtype=torch.int32),\n",
       " 'time_per_tick': 0.03125}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class SongDataSet(Dataset):\n",
    "    def __init__(self, songs, context_length=128, quantize_divisor=64):\n",
    "        self.songs = songs\n",
    "        self.dataset_idxs = build_idxs(songs, context_length)\n",
    "        self.quantize_divisor = quantize_divisor\n",
    "        self.perturbation_std = 0.05\n",
    "        self.context_length = context_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset_idxs)\n",
    "\n",
    "    def __getitem__(self, idx, different_perturbation_std=False):\n",
    "        song_idx, note_start_idx = self.dataset_idxs[idx]\n",
    "        song = self.songs[song_idx]\n",
    "        notes = song[note_start_idx:note_start_idx + context_length]\n",
    "        # Note format: [track, start, duration, pitch]\n",
    "\n",
    "        time_per_quarter_note = song[0][0] # header, first element\n",
    "        time_per_tick = (time_per_quarter_note * 4 / self.quantize_divisor).item() # quantize_divisor is ticks per measure\n",
    "\n",
    "        perturbed_notes = notes.clone()\n",
    "        # add gausian perturbations to start duration, note index 1 and 2\n",
    "        # return torch.normal(0, self.perturbation_std, perturbed_notes[:, 1].shape).shape\n",
    "        perturbation_std = self.perturbation_std\n",
    "        if different_perturbation_std is not False:\n",
    "            perturbation_std = different_perturbation_std\n",
    "        perturbed_notes[:, 1] += torch.normal(0, self.perturbation_std, perturbed_notes[:, 1].shape)\n",
    "        perturbed_notes[:, 2] += torch.normal(0, self.perturbation_std, perturbed_notes[:, 2].shape)\n",
    "        \n",
    "        \n",
    "        perturbed_notes_quantized = self.quantize_notes(perturbed_notes, time_per_tick)\n",
    "\n",
    "        notes_quantized = self.quantize_notes(notes, time_per_tick)\n",
    "\n",
    "        return {\"notes\": notes_quantized, \"perturbed_notes\": perturbed_notes_quantized, \"time_per_tick\": time_per_tick}\n",
    "        \n",
    "\n",
    "\n",
    "    def quantize_notes(self, notes, time_per_tick):\n",
    "        # subtract the start time of the note with the smallest start time from all notes (zero-based start times, even if first is negative or positive)\n",
    "        min_start_time = notes[:, 1].min()\n",
    "        notes[:, 1] -= min_start_time\n",
    "\n",
    "        quantized_notes = []\n",
    "        for note in notes:\n",
    "            quantized_note = self.quantize_note(note, time_per_tick)\n",
    "            quantized_notes.append(quantized_note) # quantizes to about 3/100 of a second (depending on the song's time signature)\n",
    "        \n",
    "        while len(quantized_notes) < self.context_length:\n",
    "            quantized_notes.append(torch.tensor([99999, 99999, 99999, 99999], dtype=torch.int32))\n",
    "        return torch.stack(quantized_notes)\n",
    "    \n",
    "        \n",
    "\n",
    "    def quantize_note(self, note, time_per_tick):\n",
    "        track, start, duration, pitch = note\n",
    "\n",
    "        track = track.item()\n",
    "        start = start.item()\n",
    "        duration = duration.item()\n",
    "        pitch = pitch.item()\n",
    "\n",
    "        start = round(start / time_per_tick)\n",
    "        duration = round(duration / time_per_tick)\n",
    "        return torch.tensor([track, start, duration, pitch], dtype=torch.int32)\n",
    "\n",
    "\n",
    "# Usage\n",
    "song_dataset = SongDataSet(dataset, context_length=128)\n",
    "song_dataset[1]\n",
    "# # Create a DataLoader\n",
    "# dataloader = DataLoader(song_dataset, batch_size=1, shuffle=True)\n",
    "# for batch in dataloader:\n",
    "#     print(batch)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My Format Analysis and Music Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_track(song_tensor, track_number):\n",
    "    \"\"\"\n",
    "    Plots the notes of a specific track from a song tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - song_tensor: torch.Tensor, the quantized notes tensor of the song.\n",
    "    - track_number: int, the track number to plot.\n",
    "    \"\"\"\n",
    "    # Filter notes for the specified track\n",
    "    track_notes = song_tensor[song_tensor[:, 0] == track_number]\n",
    "\n",
    "    if track_notes.size(0) == 0:\n",
    "        print(f\"No notes found for track {track_number}\")\n",
    "        return\n",
    "\n",
    "    # Extract start times, durations, and pitches\n",
    "    start_times = track_notes[:, 1].numpy()\n",
    "    durations = track_notes[:, 2].numpy()\n",
    "    pitches = track_notes[:, 3].numpy()\n",
    "\n",
    "    # Create a figure and axis\n",
    "    fig, ax = plt.subplots()\n",
    "\n",
    "    # Plot each note as a horizontal bar\n",
    "    for start, duration, pitch in zip(start_times, durations, pitches):\n",
    "        ax.broken_barh([(start, duration)], (pitch - 0.4, 0.8), facecolors='blue')\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel('Time (quantized ticks)')\n",
    "    ax.set_ylabel('Pitch')\n",
    "    ax.set_title(f'Track {track_number} Notes')\n",
    "\n",
    "    # Show grid\n",
    "    ax.grid(True)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming song_dataset is an instance of SongDataSet and song_tensor is a tensor from the dataset\n",
    "song_tensor = song_dataset[1]  # Get the first song tensor\n",
    "plot_track(song_tensor, track_number=0)  # Plot the first track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_all_tracks(song_tensor):\n",
    "    \"\"\"\n",
    "    Plots the notes of all tracks from a song tensor, each in its own subplot.\n",
    "\n",
    "    Parameters:\n",
    "    - song_tensor: torch.Tensor, the quantized notes tensor of the song.\n",
    "    \"\"\"\n",
    "    # Get unique track numbers\n",
    "    track_numbers = song_tensor[:, 0].unique().numpy()\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(len(track_numbers), 1, figsize=(10, 5 * len(track_numbers)), sharex=True)\n",
    "\n",
    "    if len(track_numbers) == 1:\n",
    "        axes = [axes]  # Ensure axes is iterable if there's only one track\n",
    "\n",
    "    # Plot each track\n",
    "    for ax, track_number in zip(axes, track_numbers):\n",
    "        # Filter notes for the current track\n",
    "        track_notes = song_tensor[song_tensor[:, 0] == track_number]\n",
    "\n",
    "        if track_notes.size(0) == 0:\n",
    "            continue\n",
    "\n",
    "        # Extract start times, durations, and pitches\n",
    "        start_times = track_notes[:, 1].numpy()\n",
    "        durations = track_notes[:, 2].numpy()\n",
    "        pitches = track_notes[:, 3].numpy()\n",
    "\n",
    "        # Plot each note as a horizontal bar\n",
    "        for start, duration, pitch in zip(start_times, durations, pitches):\n",
    "            ax.broken_barh([(start, duration)], (pitch - 0.4, 0.8), facecolors='blue')\n",
    "\n",
    "        # Set labels and title\n",
    "        ax.set_ylabel('Pitch')\n",
    "        ax.set_title(f'Track {track_number} Notes')\n",
    "        ax.grid(True)\n",
    "\n",
    "    # Set common x-label\n",
    "    axes[-1].set_xlabel('Time (quantized ticks)')\n",
    "\n",
    "    # Show the plot\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming song_dataset is an instance of SongDataSet and song_tensor is a tensor from the dataset\n",
    "song_tensor = song_dataset[1]  # Get the first song tensor\n",
    "plot_all_tracks(song_tensor)  # Plot all tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pretty_midi\n",
    "import torch\n",
    "\n",
    "def tensor_to_midi(tensor, output_filename, time_per_tick):\n",
    "    \"\"\"\n",
    "    Converts a tensor representation of a song back to a MIDI file.\n",
    "\n",
    "    Parameters:\n",
    "    - tensor: torch.Tensor, the quantized notes tensor of the song.\n",
    "    - output_filename: str, the filename for the output MIDI file.\n",
    "    \"\"\"\n",
    "    # Create a PrettyMIDI object\n",
    "    midi = pretty_midi.PrettyMIDI()\n",
    "\n",
    "    # Get unique track numbers\n",
    "    track_numbers = tensor[:, 0].unique().numpy()\n",
    "\n",
    "    for track_number in track_numbers:\n",
    "        # Create an Instrument instance for each track\n",
    "        instrument = pretty_midi.Instrument(program=0)  # Default to Acoustic Grand Piano\n",
    "\n",
    "        # Filter notes for the current track\n",
    "        track_notes = tensor[tensor[:, 0] == track_number]\n",
    "\n",
    "        # Extract start times, durations, and pitches\n",
    "        start_times = track_notes[:, 1].numpy()\n",
    "        durations = track_notes[:, 2].numpy()\n",
    "        pitches = track_notes[:, 3].numpy()\n",
    "\n",
    "        # Create Note objects and add them to the instrument\n",
    "        for start, duration, pitch in zip(start_times, durations, pitches):\n",
    "            note = pretty_midi.Note(\n",
    "                velocity=100,  # Default velocity\n",
    "                pitch=int(pitch),\n",
    "                start=(start*time_per_tick).item(),\n",
    "                end=((start + duration)*time_per_tick).item()\n",
    "            )\n",
    "            instrument.notes.append(note)\n",
    "\n",
    "        # Add the instrument to the PrettyMIDI object\n",
    "        midi.instruments.append(instrument)\n",
    "\n",
    "    # Write out the MIDI data\n",
    "    midi.write(output_filename)\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "song_example = song_dataset[1]  # Get the first song tensor\n",
    "notes = song_example[\"notes\"]\n",
    "perturbed_notes = song_example[\"perturbed_notes\"]\n",
    "time_per_tick = song_example[\"time_per_tick\"]\n",
    "\n",
    "tensor_to_midi(perturbed_notes, 'output_song.mid', time_per_tick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygame\n",
    "\n",
    "def play_midi_file(midi_filename):\n",
    "    \"\"\"\n",
    "    Plays a MIDI file using pygame.\n",
    "\n",
    "    Parameters:\n",
    "    - midi_filename: str, the filename of the MIDI file to play.\n",
    "    \"\"\"\n",
    "    # Initialize pygame\n",
    "    pygame.init()\n",
    "\n",
    "    # Set up the mixer to play MIDI\n",
    "    pygame.mixer.init()\n",
    "    pygame.mixer.music.load(midi_filename)\n",
    "\n",
    "    # Play the MIDI file\n",
    "    pygame.mixer.music.play()\n",
    "\n",
    "    # Keep the program running until the music stops\n",
    "    while pygame.mixer.music.get_busy():\n",
    "        pygame.time.Clock().tick(10)\n",
    "\n",
    "# Example usage\n",
    "midi_filename = 'output_song.mid'\n",
    "play_midi_file(midi_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.set_default_device(device)\n",
    "assert device == 'cuda', \"This notebook is not optimized for CPU\"\n",
    "\n",
    "config = {\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"eval_interval\": 300,\n",
    "    \"max_iters\": 3000, \n",
    "    \"H\": 16,\n",
    "    \"B\": 64,\n",
    "    \"T\": 128,\n",
    "    \"C\": 256,\n",
    "    \"feedforward_factor\": 3,\n",
    "    \"n_heads\": 6,\n",
    "    \"dropout\": 0.4,\n",
    "    \"l2_penalty\": 0.0,\n",
    "    \"n_layers\": 6,\n",
    "    \"tokenizer_vocab_size\": 4096,\n",
    "    \"git_hash\": os.popen(\"git rev-parse HEAD\").read().strip()\n",
    "}\n",
    "\n",
    "# initial\n",
    "for k,v in config.items():\n",
    "    locals ()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "\n",
    "class Head(nn.Module):\n",
    "    '''One Head of self-attention'''\n",
    "    def __init__(self, H):\n",
    "        super().__init__()\n",
    "        self.query = nn.Linear(C, H, bias=False)\n",
    "        self.key = nn.Linear(C, H, bias=False)\n",
    "        self.value = nn.Linear(C, H, bias=False)\n",
    "        # self.output = nn.Linear(H, C, bias=False) # output matrix\n",
    "        self.register_buffer('tril', torch.tril(torch.ones(T, T)))\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Query and Key matrices for the attention mechanism\n",
    "        # x: 8 tokens\n",
    "        # Q: 16 tall (arbitrary), 32 long channels\n",
    "        # K: 16 tall (arbitrary), 32 long channels\n",
    "\n",
    "        query_vectors = self.query(x)\n",
    "        key_vectors = self.key(x)\n",
    "\n",
    "\n",
    "        # Attention masking(so we can't look into the past):\n",
    "\n",
    "        tril = self.tril\n",
    "        wei = torch.zeros(T, T) \n",
    "        wei = wei.masked_fill(tril == 0, float('-inf')) # set the upper triangular to -inf\n",
    "        # xbow = wei @ x # apply the mask to the input, bag of words because simple avg.\n",
    "\n",
    "        # multiply the two to get the attention weights\n",
    "        attention_pattern = query_vectors @ key_vectors.transpose(-2, -1) # T, T\n",
    "        attention_pattern = attention_pattern / (H ** 0.5) # scale the attention pattern for numerical stability\n",
    "        attention_weights = F.softmax(attention_pattern + wei, dim=-1) # T, T (the row dimension is the query)\n",
    "        attention_weights = self.dropout(attention_weights)\n",
    "\n",
    "        value_vectors = self.value(x) # the direction we should go in the embedding space for each token (ie more blue) T, H\n",
    "\n",
    "        # apply the attention weights to the value vectors\n",
    "        context = attention_weights @ value_vectors # T, H\n",
    "\n",
    "        # project back into original space from value space\n",
    "        # return self.output(context)\n",
    "        return context\n",
    "\n",
    "x = torch.randn(B,T,C)\n",
    "head = Head(H)\n",
    "# head(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
